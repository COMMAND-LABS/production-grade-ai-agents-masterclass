# PT. 7 - Deploying the application to GCP

Now we’re going to make most of the remaining changes to our APPLICATION. So pay attention closely!

##

First of all, we DON’T want our research report written to a file but instead would like it delivered to us via email

So let’s edit the params of the Task we’re assigning to our Crew in the main.py file like so…

```python
output_pydantic=NewsResults,
output_file='report.json'
```

This change tells the Manager of our Crew to output a very specific data structure when completing this task assigned to it…

##

Let’s test this out so you see what’s happening - `python main.py`

We now see that a “structured” JSON output has been generated by our crew

We can combine the flexibility of LLMs with the predictability of traditional programming by transforming this JSON-structured output into an email body with a bit more  code…

##

Let’s add a few more helper functions…

`touch helpers/is_valid_email.py`
`touch helpers/format_news_for_email.py`

AND update the `main.py` file & the `send_email.py` file…

```python - main.py L70-73
email_list = ["tad@cmdlabs.io"]
for email in email_list:
    if bool(email) and is_valid_email(email):
        send_email([email.strip()], format_news_for_email(crew_output.pydantic, current_date))
```

```python - send_email.py
import requests
import os

def send_email(recipients: list[str], body: str):
    print("Sending email...")
    requests.post(
      "https://api.mailgun.net/v3/sandboxd7c358e02f26415dbb7329dd994a8334.mailgun.org/messages",
      auth=("api", os.getenv("MAILGUN_API_KEY")),
      data={
        "from": "A.I. News Reporter <noreply@mail.wishbliss.link>",
        "to": recipients,
        "subject": "Hello",
        "html": body,
      }
    )
```

And now if we test our script again let’s see what happens…

`python main.py`

Our agents generated a json-structured news report and we then used it to populate an email template plus we received the email in our inbox…

##

Next, let’s deploy this application to Google Cloud Run so we can automatically get regular reports from our Crew regardless of if our computer is turned on or off…

##

We’re going to use another product in the GCP suite called Secret Manager

Secret Manager is a product for storing sensitive data like API keys and passwords…

```sh
gcloud services enable secretmanager.googleapis.com --project $PROJECT_ID
gcloud services list --enabled
```

Now that this API is enabled in our GCP account, we can store sensitive data into it like so…

## 

https://console.cloud.google.com/security/secret-manager?referrer=search&hl=en&project=hthtogcrj

This is the command template for storing secrets in “Secret Manager”

```sh
echo -n "<SECRET>" | gcloud secrets create $SECRET_NAME --data-file=-
```

So this is how we would add our OPENAI_API_KEY to “Secret Manager”…

```sh
echo -n "<YOUR_OPENAI_API_KEY>" | gcloud secrets create OPENAI_API_KEY --project $PROJECT_ID --data-file=-
```

We pipe the value of our OPENAI_API_KEY into this “gcloud” command…

https://console.cloud.google.com/security/secret-manager?referrer=search&hl=en&project=hthaogcrj-practice

& this is how we would add our MAILGUN_API_KEY to “Secret Manager”

```sh
echo -n "<YOUR_MAILGUN_API_KEY>" | gcloud secrets create MAILGUN_API_KEY --data-file=-
```

##

https://console.cloud.google.com/security/secret-manager?referrer=search&hl=en&project=hthaogcrj-practice

FYI, as a quick sidenote, this is the command for updating a secret to have a new value…

```sh
echo "YOUR_NEW_SECRET_VALUE" | gcloud secrets versions add OPENAI_API_KEY --data-file=-
```

##

Anyways…

The last thing we need to do before testing the CICD automation is give the Cloud Run API running in our GCP project permissions to access these secrets in Secret Manager…

So let’s enter the following commands…

```sh
gcloud secrets add-iam-policy-binding OPENAI_API_KEY \
  --member="serviceAccount:$PROJECT_NUMBER-compute@developer.gserviceaccount.com" \
  --role="roles/secretmanager.secretAccessor"

gcloud secrets add-iam-policy-binding MAILGUN_API_KEY \
  --member="serviceAccount:$PROJECT_NUMBER-compute@developer.gserviceaccount.com" \
  --role="roles/secretmanager.secretAccessor"
```

##

Now let’s take a look at our cicd.yaml automation…

For the `gcloud run jobs deploy` step of our CICD script, let’s add a new flag called `—set-secrets` and pass in the list of ENVIRONMENT_VARIABLES for our job by referencing their values in “Secret Manager” like so…

```sh
--set-secrets "OPENAI_API_KEY=projects/${{ env.PROJECT_NUMBER }}/secrets/OPENAI_API_KEY:latest,MAILGUN_API_KEY=projects/${{ env.PROJECT_NUMBER }}/secrets/MAILGUN_API_KEY:latest" 
```

Let’s re-run our CICD script by pushing this change to the `main` branch in GitHub and see what happens…

##

If the build fails be sure to add the C/C++ libraries required by CrewAI in the Dockerfile.prod on lines 4-6

```Dockerfile
# Adding C build tools to the image
RUN apt-get update && \
    apt-get install -y build-essential
# Set the working directory in the container
```

##

Let’s re-run our CICD script by pushing this change to the `main` branch in GitHub and see what happens…

Ok! That looks like it worked!

##

Let’s trigger our job to confirm we receive an email

`gcloud run jobs execute first-crj-ever --region us-east1 --project $PROJECT_ID`

And we do indeed see an email arrive in our inbox with an A.I. generated report

So we’re looking good…

## 

Before we wrap up PART 7, let’s discuss a few of the flags available to us on our Cloud Run job…

- CPU
- memory
- maxRetries
- timeoutSeconds

Because Multi-Agent systems are probabilistic, they generate a variable amount of data each time they are ran. And at times I’ve seen them generate so much text that they consume all of the memory allocated to them when running in Cloud Run and crash. So to make sure our Agents have plenty of resources to be successful, let’s double the default amount of memory allocated to the container running our job and bump the amount of retries our job is allowed to make from 3 to 5 before Cloud Run reports the job as failed to us. You can tune this to your application’s needs when the time comes

```sh
--memory 1Gi
--max-retries 5
```

##

Next up we’ll add a Monitoring Tool called AgentsOps. AgentsOps will give us easier insight into how the A.I. Agents powering our application are performing compared to observing them through the GCP console. Once you get to point where you have dozens or even hundred of Agents working for you, you’re going to need a tool like AgentOps for easily monitoring them and getting an overview of how they are doing.
